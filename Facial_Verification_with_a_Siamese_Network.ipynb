{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aFhuk7qPNxkd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.17.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.17.0) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sithira bimsara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.17.0 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eRBoKvkLN8AE"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "q7fKkRbtOXMU"
   },
   "outputs": [],
   "source": [
    "# Import tensorflow dependencies\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-bGA2FNeOmAD"
   },
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2B_i9uUfPlD7"
   },
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dOYEjDSTP_W9"
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'data\\\\positive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Making the directories\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPOS_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(NEG_PATH)\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(ANC_PATH)\n",
      "File \u001b[1;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'data\\\\positive'"
     ]
    }
   ],
   "source": [
    "# Making the directories\n",
    "os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incompress the labelled faces in the wild dataset\n",
    "!tar -xf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tp8KqJIW4V8"
   },
   "outputs": [],
   "source": [
    "# Move LFW images from the exisitng repository to the following repository data/negative\n",
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw', directory)):\n",
    "        EX_PATH = os.path.join('lfw', directory, file)\n",
    "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "        os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DK6fRhkEebgE"
   },
   "outputs": [],
   "source": [
    "# Import uuid\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "66o9pMFHePeE"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Establish a connection to the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "        \n",
    "    # Cut down to 250x250\n",
    "    frame = frame[120:120+250, 200:200+250, :]\n",
    "\n",
    "    # Show image back to screen\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "\n",
    "    # Wait for the key press\n",
    "    key = cv2.waitKey(1) & 0XFF\n",
    "    \n",
    "    # Capturing anchors\n",
    "    if key == ord('a'):\n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "            \n",
    "\n",
    "    # Capturing positives\n",
    "    if key == ord('p'):\n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "           \n",
    "\n",
    "    # Breaking gracefully when 'q' is pressed\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam\n",
    "cap.release()\n",
    "\n",
    "# Close the image show frame\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image from a file\n",
    "img = cv2.imread('data/anchor/00b5eae7-92ac-11ef-8d26-f209a11ea55b.jpg')\n",
    "# Display the image in a window\n",
    "cv2.imshow('Image', img)\n",
    "\n",
    "# Wait indefinitely until a key is pressed\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close the window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BTrsVxCkQN7"
   },
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(300)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmLxDb7fomcy"
   },
   "outputs": [],
   "source": [
    "dir_test = anchor.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSt4UAseonsr"
   },
   "outputs": [],
   "source": [
    "dir_test.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gmVdENapXrx"
   },
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "\n",
    "  # Read in image from file path\n",
    "  byte_img = tf.io.read_file(file_path)\n",
    "  # Load in the image\n",
    "  img = tf.io.decode_jpeg(byte_img)\n",
    "  # Preprocessing the image - resizing the image to be 100x100x3\n",
    "  img = tf.image.resize(img, (100, 100))\n",
    "  # Scale image to be between 0 and 1\n",
    "  img = img / 255.0\n",
    "  # Return image\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqjpw0rY6kay"
   },
   "outputs": [],
   "source": [
    "img = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hn4Z9qaspi1I"
   },
   "outputs": [],
   "source": [
    "dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0XFyqcA7rb8"
   },
   "outputs": [],
   "source": [
    "# Creating labelled dataset\n",
    "\n",
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pMJi8UO8-cq"
   },
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8O4bGhM9AZa"
   },
   "outputs": [],
   "source": [
    "samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "el3QGRHt9oiy"
   },
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DCDqsXH-1AE"
   },
   "outputs": [],
   "source": [
    "# Dataloader pipelien\n",
    "\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "naRVqz_6_7X4"
   },
   "outputs": [],
   "source": [
    "# Training partition\n",
    "\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "\n",
    "# Passing the data as batch of 16 images\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xL6qXzwAzXD"
   },
   "outputs": [],
   "source": [
    "# Tesing partition\n",
    "test_data = data.skip(round(len(data)*.7)) # Skipping train 70% data\n",
    "test_data = test_data.take(round(len(data)*.3)) # Grabbing the last 30% data as test partition\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QtZljqOSqf_S"
   },
   "outputs": [],
   "source": [
    "# Embedding layer\n",
    "\n",
    "def make_embedding():\n",
    "    inp = Input(shape=(100,100,3), name='input_image') # Input Layer\n",
    "\n",
    "    # First block\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp) # Convolution Layer\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1) # Max pooling layer\n",
    "\n",
    "    # Second block\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "\n",
    "    # Third block\n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "\n",
    "    # Final embedding block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "\n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2XqRGoPsJjy"
   },
   "outputs": [],
   "source": [
    "embedding = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vw-K6WOWsKgi"
   },
   "outputs": [],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPn5cWc0s5gh"
   },
   "outputs": [],
   "source": [
    "# Distance layer\n",
    "\n",
    "class L1Dist(Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "\n",
    "  # Similarity calculation\n",
    "  def call(self, input_embedding, validation_embedding):\n",
    "    return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YXQNHtIuOFQ"
   },
   "outputs": [],
   "source": [
    "l1 = L1Dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qq2bK74wEde"
   },
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "\n",
    "  # Anchor image input in the network\n",
    "  input_image = Input(name='input_img', shape=(100,100,3))\n",
    "\n",
    "  # Validation image in the network\n",
    "  validation_image = Input(name='validation_img', shape=(100,100,3))\n",
    "\n",
    "  # Combine siamese distance components\n",
    "  siamese_layer = L1Dist()\n",
    "  siamese_layer._name = 'distance'\n",
    "  distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "\n",
    "  # Classification Layer\n",
    "  classifier = Dense(1, activation='sigmoid')(distances)\n",
    "\n",
    "  return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
